{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"ChBbac4y8PPq","executionInfo":{"status":"ok","timestamp":1736361322864,"user_tz":300,"elapsed":3924,"user":{"displayName":"Aarush Sheth","userId":"06423698602659898506"}}},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"klmu3ZG08PPr","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1736361324641,"user_tz":300,"elapsed":458,"user":{"displayName":"Aarush Sheth","userId":"06423698602659898506"}},"outputId":"fa1ecdd7-ce0a-4735-f613-055639e0ca5f"},"outputs":[{"output_type":"stream","name":"stdout","text":["32033\n","15\n","['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"]}],"source":["words = open('names.txt', 'r').read().splitlines()\n","print(len(words))\n","print(max(len(w) for w in words))\n","print(words[:8])"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"BCQomLE_8PPs","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1736361347982,"user_tz":300,"elapsed":314,"user":{"displayName":"Aarush Sheth","userId":"06423698602659898506"}},"outputId":"36e7ba2c-ad6d-4020-94b1-b91adde51795"},"outputs":[{"output_type":"stream","name":"stdout","text":["{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n","27\n"]}],"source":["chars = sorted(list(set(''.join(words))))\n","stoi = {s:i+1 for i,s in enumerate(chars)}\n","stoi['.'] = 0\n","itos = {i:s for s,i in stoi.items()}\n","vocab_size = len(itos)\n","print(itos)\n","print(vocab_size)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"V_zt2QHr8PPs","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1736361368274,"user_tz":300,"elapsed":1077,"user":{"displayName":"Aarush Sheth","userId":"06423698602659898506"}},"outputId":"00557044-67c8-43ad-9425-ddb61b5945e0"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([182389, 3]) torch.Size([182389])\n","torch.Size([22878, 3]) torch.Size([22878])\n","torch.Size([22879, 3]) torch.Size([22879])\n"]}],"source":["block_size = 3\n","\n","def build_dataset(words):\n","  X, Y = [], []\n","\n","  for w in words:\n","    context = [0] * block_size\n","    for ch in w + '.':\n","      ix = stoi[ch]\n","      X.append(context)\n","      Y.append(ix)\n","      context = context[1:] + [ix] # crop and append\n","\n","  X = torch.tensor(X)\n","  Y = torch.tensor(Y)\n","  print(X.shape, Y.shape)\n","  return X, Y\n","\n","import random\n","random.seed(4342)\n","random.shuffle(words)\n","n1 = int(0.8*len(words))\n","n2 = int(0.9*len(words))\n","\n","Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n","Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n","Xte,  Yte  = build_dataset(words[n2:])     # 10%"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"MJPU8HT08PPu","executionInfo":{"status":"ok","timestamp":1736361373882,"user_tz":300,"elapsed":335,"user":{"displayName":"Aarush Sheth","userId":"06423698602659898506"}}},"outputs":[],"source":["def cmp(s, dt, t):\n","  ex = torch.all(dt == t.grad).item()\n","  app = torch.allclose(dt, t.grad)\n","  maxdiff = (dt - t.grad).abs().max().item()\n","  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"ZlFLjQyT8PPu","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1736361440078,"user_tz":300,"elapsed":5,"user":{"displayName":"Aarush Sheth","userId":"06423698602659898506"}},"outputId":"9e587c39-8d44-49a7-9dd1-6aa2b5ccc2a1"},"outputs":[{"output_type":"stream","name":"stdout","text":["4137\n"]}],"source":["n_embd = 10 # dim of embedding vectors\n","n_hidden = 64 # neurons in hidden layer\n","\n","g = torch.Generator().manual_seed(67808)\n","C  = torch.randn((vocab_size, n_embd),            generator=g)\n","# Layer 1\n","W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n","b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n","# Layer 2\n","W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n","b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n","# BatchNorm parameters\n","bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n","bnbias = torch.randn((1, n_hidden))*0.1\n","\n","\n","parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n","print(sum(p.nelement() for p in parameters))\n","for p in parameters:\n","  p.requires_grad = True"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"QY-y96Y48PPv","executionInfo":{"status":"ok","timestamp":1736361449200,"user_tz":300,"elapsed":241,"user":{"displayName":"Aarush Sheth","userId":"06423698602659898506"}}},"outputs":[],"source":["batch_size = 32\n","n = batch_size\n","ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n","Xb, Yb = Xtr[ix], Ytr[ix]"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"8ofj1s6d8PPv","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1736361515548,"user_tz":300,"elapsed":263,"user":{"displayName":"Aarush Sheth","userId":"06423698602659898506"}},"outputId":"4e035e9c-8f32-4752-8091-bbfa51f71725"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(3.3979, grad_fn=<NegBackward0>)"]},"metadata":{},"execution_count":11}],"source":["emb = C[Xb]\n","embcat = emb.view(emb.shape[0], -1)\n","hprebn = embcat @ W1 + b1\n","bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n","bndiff = hprebn - bnmeani\n","bndiff2 = bndiff**2\n","bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # Bessel's correction\n","bnvar_inv = (bnvar + 1e-5)**-0.5\n","bnraw = bndiff * bnvar_inv\n","hpreact = bngain * bnraw + bnbias\n","h = torch.tanh(hpreact)\n","logits = h @ W2 + b2\n","logit_maxes = logits.max(1, keepdim=True).values\n","norm_logits = logits - logit_maxes # subtracted max for numerical stability\n","counts = norm_logits.exp()\n","counts_sum = counts.sum(1, keepdims=True)\n","counts_sum_inv = counts_sum**-1\n","probs = counts * counts_sum_inv\n","logprobs = probs.log()\n","loss = -logprobs[range(n), Yb].mean()\n","\n","for p in parameters:\n","  p.grad = None\n","for t in [logprobs, probs, counts, counts_sum, counts_sum_inv,\n","          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n","         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n","         embcat, emb]:\n","  t.retain_grad()\n","loss.backward()\n","loss"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"mO-8aqxK8PPw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736362233520,"user_tz":300,"elapsed":461,"user":{"displayName":"Aarush Sheth","userId":"06423698602659898506"}},"outputId":"4b2a8d54-d1b8-4096-b14b-2cb332726e39"},"outputs":[{"output_type":"stream","name":"stdout","text":["logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n","probs           | exact: True  | approximate: True  | maxdiff: 0.0\n","counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n","counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n","counts          | exact: True  | approximate: True  | maxdiff: 0.0\n","norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n","logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n","logits          | exact: True  | approximate: True  | maxdiff: 0.0\n","h               | exact: True  | approximate: True  | maxdiff: 0.0\n","W2              | exact: True  | approximate: True  | maxdiff: 0.0\n","b2              | exact: True  | approximate: True  | maxdiff: 0.0\n","hpreact         | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n","bngain          | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n","bnbias          | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n","bnraw           | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n","bnvar_inv       | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n","bnvar           | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n","bndiff2         | exact: False | approximate: True  | maxdiff: 2.9103830456733704e-11\n","bndiff          | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n","bnmeani         | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n","hprebn          | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n","embcat          | exact: False | approximate: True  | maxdiff: 1.3969838619232178e-09\n","W1              | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n","b1              | exact: False | approximate: True  | maxdiff: 2.3865140974521637e-09\n","emb             | exact: False | approximate: True  | maxdiff: 1.3969838619232178e-09\n","C               | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n"]}],"source":["# Exercise 1: backprop through the whole thing manually,\n","# backpropagating through exactly all of the variables\n","# as they are defined in the forward pass above, one by one\n","\n","# -----------------\n","# YOUR CODE HERE :)\n","# -----------------\n","\n","# Gradient of loss w.r.t logprobs\n","dlogprobs = torch.zeros_like(logprobs)\n","dlogprobs[range(n), Yb] = -1 / n\n","cmp('logprobs', dlogprobs, logprobs)\n","\n","# Gradient of logprobs w.r.t probs\n","dprobs = dlogprobs / probs\n","cmp('probs', dprobs, probs)\n","\n","# Gradient of probs w.r.t counts_sum_inv\n","dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n","cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n","\n","# Gradient of counts_sum_inv w.r.t counts_sum\n","dcounts_sum = dcounts_sum_inv * -1 * counts_sum**-2\n","cmp('counts_sum', dcounts_sum, counts_sum)\n","\n","# Gradient of counts_sum and probs w.r.t counts\n","dcounts = dcounts_sum + counts_sum_inv * dprobs\n","cmp('counts', dcounts, counts)\n","\n","# Gradient of counts w.r.t norm_logits\n","dnorm_logits = dcounts * norm_logits.exp()\n","cmp('norm_logits', dnorm_logits, norm_logits)\n","\n","# Gradient of norm_logits w.r.t logit_maxes\n","dlogit_maxes = -dnorm_logits.sum(1, keepdim=True)\n","cmp('logit_maxes', dlogit_maxes, logit_maxes)\n","\n","# Gradient of norm_logits w.r.t logits\n","dlogits = dnorm_logits.clone()\n","dlogits[torch.arange(dlogits.size(0)), logits.argmax(1)] += dlogit_maxes.view([-1])\n","cmp('logits', dlogits, logits)\n","\n","# Gradients of logits w.r.t h, W2, and b2\n","dh = dlogits @ W2.T\n","cmp('h', dh, h)\n","\n","dW2 = h.T @ dlogits\n","cmp('W2', dW2, W2)\n","\n","db2 = dlogits.sum(0)\n","cmp('b2', db2, b2)\n","\n","# Gradient of h w.r.t hpreact\n","dhpreact = dh * (1 - h**2)\n","cmp('hpreact', dhpreact, hpreact)\n","\n","# Gradients of hpreact w.r.t bngain, bnbias, and bnraw\n","dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n","cmp('bngain', dbngain, bngain)\n","\n","dbnbias = dhpreact.sum(0, keepdim=True)\n","cmp('bnbias', dbnbias, bnbias)\n","\n","dbnraw = dhpreact * bngain\n","cmp('bnraw', dbnraw, bnraw)\n","\n","# Gradients of bnraw w.r.t bnvar_inv and bndiff\n","dbnvar_inv = (dbnraw * bndiff).sum(0, keepdim=True)\n","cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n","\n","dbnvar = dbnvar_inv * -0.5 * (bnvar + 1e-5)**-1.5\n","cmp('bnvar', dbnvar, bnvar)\n","\n","dbndiff2 = dbnvar * (1. / (n - 1))\n","cmp('bndiff2', dbndiff2, bndiff2)\n","\n","dbndiff = dbnraw * bnvar_inv + dbndiff2 * 2 * bndiff\n","cmp('bndiff', dbndiff, bndiff)\n","\n","# Gradients of bndiff w.r.t bnmeani and hprebn\n","dbnmeani = -dbndiff.sum(0, keepdim=True)\n","cmp('bnmeani', dbnmeani, bnmeani)\n","\n","dhprebn = dbndiff.clone()\n","dhprebn += dbnmeani * (1. / n)\n","cmp('hprebn', dhprebn, hprebn)\n","\n","# Gradients of hprebn w.r.t embcat, W1, and b1\n","dembcat = dhprebn @ W1.T\n","cmp('embcat', dembcat, embcat)\n","\n","dW1 = embcat.T @ dhprebn\n","cmp('W1', dW1, W1)\n","\n","db1 = dhprebn.sum(0)\n","cmp('b1', db1, b1)\n","\n","# Gradient of embcat w.r.t emb\n","demb = dembcat.clone().view(emb.shape)\n","cmp('emb', demb, emb)\n","\n","# Gradient of emb w.r.t C\n","dC = torch.tensordot(F.one_hot(Xb, num_classes=vocab_size).float(), demb, dims=([0, 1], [0, 1]))\n","cmp('C', dC, C)\n"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"ebLtYji_8PPw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736362245804,"user_tz":300,"elapsed":395,"user":{"displayName":"Aarush Sheth","userId":"06423698602659898506"}},"outputId":"9eb6bbf6-f585-4cff-862f-1233dfab4cd5"},"outputs":[{"output_type":"stream","name":"stdout","text":["3.397850751876831 diff: -2.384185791015625e-07\n"]}],"source":["# Exercise 2: backprop through cross_entropy but all in one go\n","# to complete this challenge look at the mathematical expression of the loss,\n","# take the derivative, simplify the expression, and just write it out\n","\n","# forward pass\n","\n","# before:\n","# logit_maxes = logits.max(1, keepdim=True).values\n","# norm_logits = logits - logit_maxes # subtract max for numerical stability\n","# counts = norm_logits.exp()\n","# counts_sum = counts.sum(1, keepdims=True)\n","# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n","# probs = counts * counts_sum_inv\n","# logprobs = probs.log()\n","# loss = -logprobs[range(n), Yb].mean()\n","\n","# now:\n","loss_fast = F.cross_entropy(logits, Yb)\n","print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"-gCXbB4C8PPx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736362316277,"user_tz":300,"elapsed":265,"user":{"displayName":"Aarush Sheth","userId":"06423698602659898506"}},"outputId":"22cfdd73-fa3c-4aa0-c42e-a69a895ffd3e"},"outputs":[{"output_type":"stream","name":"stdout","text":["logits          | exact: False | approximate: True  | maxdiff: 5.587935447692871e-09\n"]}],"source":["# backward pass\n","\n","# -----------------\n","# YOUR CODE HERE :)\n","# Compute dlogits directly for cross-entropy loss\n","\n","# Compute softmax\n","probs = logits.softmax(dim=1)\n","\n","# Create one-hot encoding for the true labels\n","one_hot_Yb = F.one_hot(Yb, num_classes=logits.size(1)).float()\n","\n","# Compute gradient of loss w.r.t logits\n","dlogits = (probs - one_hot_Yb) / n\n","\n","cmp('logits', dlogits, logits)\n","# -----------------\n"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"hd-MkhB68PPy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736362331000,"user_tz":300,"elapsed":260,"user":{"displayName":"Aarush Sheth","userId":"06423698602659898506"}},"outputId":"98cf8eb3-d16e-4859-9b6f-40ca5139c0a1"},"outputs":[{"output_type":"stream","name":"stdout","text":["max diff: tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n"]}],"source":["# Exercise 3: backprop through batchnorm but all in one go\n","# to complete this challenge look at the mathematical expression of the output of batchnorm,\n","# take the derivative w.r.t. its input, simplify the expression, and just write it out\n","# BatchNorm paper: https://arxiv.org/abs/1502.03167\n","\n","# forward pass\n","\n","# before:\n","# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n","# bndiff = hprebn - bnmeani\n","# bndiff2 = bndiff**2\n","# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n","# bnvar_inv = (bnvar + 1e-5)**-0.5\n","# bnraw = bndiff * bnvar_inv\n","# hpreact = bngain * bnraw + bnbias\n","\n","# now:\n","hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n","print('max diff:', (hpreact_fast - hpreact).abs().max())"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"POdeZSKT8PPy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736362418728,"user_tz":300,"elapsed":268,"user":{"displayName":"Aarush Sheth","userId":"06423698602659898506"}},"outputId":"600abf6d-8c0b-49eb-e9e4-974a399a41a1"},"outputs":[{"output_type":"stream","name":"stdout","text":["hprebn          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"]}],"source":["# backward pass\n","\n","# before we had:\n","# dbnraw = bngain * dhpreact\n","# dbndiff = bnvar_inv * dbnraw\n","# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n","# dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n","# dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n","# dbndiff += (2*bndiff) * dbndiff2\n","# dhprebn = dbndiff.clone()\n","# dbnmeani = (-dbndiff).sum(0)\n","# dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n","\n","# calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n","# (you'll also need to use some of the variables from the forward pass up above)\n","\n","# -----------------\n","# YOUR CODE HERE :)\n","dhprebn = bngain * bnvar_inv / n * (n * dhpreact - dhpreact.sum(0) - n / (n - 1) * bnraw * (dhpreact * bnraw).sum(0))\n","\n","\n","cmp('hprebn', dhprebn, hprebn)"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"wPy8DhqB8PPz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736362933072,"user_tz":300,"elapsed":399245,"user":{"displayName":"Aarush Sheth","userId":"06423698602659898506"}},"outputId":"5a386827-b584-4700-ef01-6d0d7eb38859"},"outputs":[{"output_type":"stream","name":"stdout","text":["12297\n","      0/ 200000: 3.6379\n","  10000/ 200000: 2.5988\n","  20000/ 200000: 2.3178\n","  30000/ 200000: 2.5334\n","  40000/ 200000: 2.2282\n","  50000/ 200000: 2.2459\n","  60000/ 200000: 1.9947\n","  70000/ 200000: 2.1075\n","  80000/ 200000: 2.3684\n","  90000/ 200000: 2.3478\n"," 100000/ 200000: 2.2692\n"," 110000/ 200000: 1.8890\n"," 120000/ 200000: 2.2152\n"," 130000/ 200000: 2.1798\n"," 140000/ 200000: 1.8690\n"," 150000/ 200000: 1.7869\n"," 160000/ 200000: 2.3595\n"," 170000/ 200000: 2.2159\n"," 180000/ 200000: 2.3390\n"," 190000/ 200000: 1.7842\n"]}],"source":["# Exercise 4: putting it all together!\n","# Train the MLP neural net with your own backward pass\n","\n","# init\n","n_embd = 10 # the dimensionality of the character embedding vectors\n","n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n","\n","g = torch.Generator().manual_seed(2147483647) # for reproducibility\n","C  = torch.randn((vocab_size, n_embd),            generator=g)\n","# Layer 1\n","W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n","b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n","# Layer 2\n","W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n","b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n","# BatchNorm parameters\n","bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n","bnbias = torch.randn((1, n_hidden))*0.1\n","\n","parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n","print(sum(p.nelement() for p in parameters)) # number of parameters in total\n","for p in parameters:\n","  p.requires_grad = True\n","\n","# same optimization as last time\n","max_steps = 200000\n","batch_size = 32\n","n = batch_size # convenience\n","lossi = []\n","\n","# use this context manager for efficiency once your backward pass is written (TODO)\n","#with torch.no_grad():\n","\n","# kick off optimization\n","for i in range(max_steps):\n","\n","  # minibatch construct\n","  ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n","  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n","\n","  # forward pass\n","  emb = C[Xb] # embed the characters into vectors\n","  embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n","  # Linear layer\n","  hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n","  # BatchNorm layer\n","  # -------------------------------------------------------------\n","  bnmean = hprebn.mean(0, keepdim=True)\n","  bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n","  bnvar_inv = (bnvar + 1e-5)**-0.5\n","  bnraw = (hprebn - bnmean) * bnvar_inv\n","  hpreact = bngain * bnraw + bnbias\n","  # -------------------------------------------------------------\n","  # Non-linearity\n","  h = torch.tanh(hpreact) # hidden layer\n","  logits = h @ W2 + b2 # output layer\n","  loss = F.cross_entropy(logits, Yb) # loss function\n","\n","  # backward pass\n","  for p in parameters:\n","    p.grad = None\n","  loss.backward() # use this for correctness comparisons, delete it later!\n","\n","  # manual backprop! #swole_doge_meme\n","  # -----------------\n","  # YOUR CODE HERE :)\n","  # manual backpropagation\n","# Start from the loss gradient w.r.t. logits\n","  n = logits.shape[0]  # batch size\n","\n","  # Cross-entropy gradient\n","  probs = logits.softmax(dim=1)\n","  one_hot_Yb = F.one_hot(Yb, num_classes=logits.size(1)).float()\n","  dlogits = (probs - one_hot_Yb) / n\n","\n","  # Gradients w.r.t. W2 and b2\n","  dW2 = h.T @ dlogits\n","  db2 = dlogits.sum(0)\n","\n","  # Backprop through output layer\n","  dh = dlogits @ W2.T\n","\n","  # Gradients w.r.t. hpreact (tanh non-linearity)\n","  dhpreact = dh * (1 - h**2)\n","\n","  # BatchNorm gradients\n","  dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n","  dbnbias = dhpreact.sum(0, keepdim=True)\n","  dbnraw = dhpreact * bngain\n","  dbndiff = dbnraw * bnvar_inv\n","  dbnvar_inv = (dbnraw * (hprebn - bnmean)).sum(0, keepdim=True)\n","  dbnvar = dbnvar_inv * -0.5 * (bnvar + 1e-5)**-1.5\n","  dbndiff2 = dbnvar * (1. / (n - 1))\n","  dbndiff += 2 * (hprebn - bnmean) * dbndiff2\n","  dbnmean = -dbndiff.sum(0, keepdim=True)\n","  dhprebn = dbndiff + dbnmean / n\n","\n","  # Gradients w.r.t. W1 and b1\n","  dW1 = embcat.T @ dhprebn\n","  db1 = dhprebn.sum(0)\n","\n","  # Backprop through embedding concatenation\n","  dembcat = dhprebn @ W1.T\n","\n","  # Reshape for embedding gradients\n","  demb = dembcat.view(emb.shape)\n","\n","  # Gradients w.r.t. C\n","  dC = torch.tensordot(F.one_hot(Xb, num_classes=vocab_size).float(), demb, dims=([0, 1], [0, 1]))\n","\n","  # Store gradients\n","  grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","  dC, dW1, db1, dW2, db2, dbngain, dbnbias = None, None, None, None, None, None, None\n","  grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n","  # -----------------\n","\n","  # update\n","  lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n","  for p, grad in zip(parameters, grads):\n","    p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n","    #p.data += -lr * grad # new way of swole doge TODO: enable\n","\n","  # track stats\n","  if i % 10000 == 0: # print every once in a while\n","    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n","  lossi.append(loss.log10().item())\n"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"ZEpI0hMW8PPz","executionInfo":{"status":"ok","timestamp":1736362970426,"user_tz":300,"elapsed":244,"user":{"displayName":"Aarush Sheth","userId":"06423698602659898506"}}},"outputs":[],"source":["# useful for checking your gradients\n","# for p,g in zip(parameters, grads):\n","  # cmp(str(tuple(p.shape)), g, p)"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"KImLWNoh8PP0","executionInfo":{"status":"ok","timestamp":1736362975140,"user_tz":300,"elapsed":961,"user":{"displayName":"Aarush Sheth","userId":"06423698602659898506"}}},"outputs":[],"source":["# calibrate the batch norm at the end of training\n","\n","with torch.no_grad():\n","  # pass the training set through\n","  emb = C[Xtr]\n","  embcat = emb.view(emb.shape[0], -1)\n","  hpreact = embcat @ W1 + b1\n","  # measure the mean/std over the entire training set\n","  bnmean = hpreact.mean(0, keepdim=True)\n","  bnvar = hpreact.var(0, keepdim=True, unbiased=True)\n"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"6aFnP_Zc8PP0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736362979025,"user_tz":300,"elapsed":1395,"user":{"displayName":"Aarush Sheth","userId":"06423698602659898506"}},"outputId":"0174eb9a-29fd-4009-c93c-052c89376437"},"outputs":[{"output_type":"stream","name":"stdout","text":["train 2.0716540813446045\n","val 2.113229751586914\n"]}],"source":["# evaluate train and val loss\n","\n","@torch.no_grad() # this decorator disables gradient tracking\n","def split_loss(split):\n","  x,y = {\n","    'train': (Xtr, Ytr),\n","    'val': (Xdev, Ydev),\n","    'test': (Xte, Yte),\n","  }[split]\n","  emb = C[x] # (N, block_size, n_embd)\n","  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n","  hpreact = embcat @ W1 + b1\n","  hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n","  h = torch.tanh(hpreact) # (N, n_hidden)\n","  logits = h @ W2 + b2 # (N, vocab_size)\n","  loss = F.cross_entropy(logits, y)\n","  print(split, loss.item())\n","\n","split_loss('train')\n","split_loss('val')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"esWqmhyj8PP1"},"outputs":[],"source":["# I achieved:\n","# train 2.0718822479248047\n","# val 2.1162495613098145"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"xHeQNv3s8PP1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736362986307,"user_tz":300,"elapsed":338,"user":{"displayName":"Aarush Sheth","userId":"06423698602659898506"}},"outputId":"2f9ad72a-b37b-401b-c4a2-e0c6fa76c4c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["mon.\n","ammyah.\n","see.\n","mad.\n","ryal.\n","rethruthadra.\n","gradelyn.\n","eliah.\n","miloe.\n","leigh.\n","estanaraelyzion.\n","kalin.\n","shub.\n","rishira.\n","stin.\n","joselynn.\n","novana.\n","ubrence.\n","ryylani.\n","els.\n"]}],"source":["# sample from the model\n","g = torch.Generator().manual_seed(2147483647 + 10)\n","\n","for _ in range(20):\n","\n","    out = []\n","    context = [0] * block_size # initialize with all ...\n","    while True:\n","      # forward pass\n","      emb = C[torch.tensor([context])] # (1,block_size,d)\n","      embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n","      hpreact = embcat @ W1 + b1\n","      hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n","      h = torch.tanh(hpreact) # (N, n_hidden)\n","      logits = h @ W2 + b2 # (N, vocab_size)\n","      # sample\n","      probs = F.softmax(logits, dim=1)\n","      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n","      context = context[1:] + [ix]\n","      out.append(ix)\n","      if ix == 0:\n","        break\n","\n","    print(''.join(itos[i] for i in out))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[{"file_id":"1WV2oi2fh9XXyldh02wupFQX0wh5ZC-z-","timestamp":1736361250570}]}},"nbformat":4,"nbformat_minor":0}